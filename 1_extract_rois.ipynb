{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the notebook is to extract the regions of interest (ROIs) of a resting state image using a segmentation image. This notebook only deals with a subject but can easily be extended to multiple subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with real-world data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dowloading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to download the dataset. Which you can find on this [website](https://db.humanconnectome.org/app/template/Login.vm;jsessionid=F82708079FFD7C01858D47841C617389). You will need to register yourself as an user to get acess to the data, but it should be straightforward. Once you have logged in, choose the project `WU-Minn HCP Data - 1200 Subjects` and dowload the dataset for one subject. \n",
    "\n",
    "You will need to download the anatomical data and the resting state data separetly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring and Visualising your Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, fsl installation runned smoothly and you can now use it to visualise brain images. \n",
    "\n",
    "**Exercise:** Try to get a fealing of how the anatomical and the resting state image look like. They are called  `T1w_restore.nii.gz` and `rfMRI_REST1_LR.nii.gz`/`rfMRI_REST1_RL.nii.gz`\n",
    "\n",
    "Note: To use fsl you will need to call it from the terminal. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, when you have a new image you want to check if it is in the standard template coordinates or native space. In case your image is on native space you will need to register it to MNI. A simple way of doing that is by visualising the image using `fslview` and overlaying a template that is already on MNI space (e.g. `MNI152_T1_2mm.nii.gz`). If fsl complains that means that the image is not on the standard space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Are both anatomical and functional image in the standart space?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are completly lost and have no idea of what I mean by MNI, you can take a look at this slides:\n",
    "https://fsl.fmrib.ox.ac.uk/fslcourse/lectures/reg.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Together with this notebook you should have received a segmentation image (`seg_aparc_82roi_2mm.nii.gz`) and a text file called `Lookuptable`.\n",
    "\n",
    "The segmenation image is a labeled atlas where each region has been labeled with a specific intensity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Visualise the segmentation image using `fslview`. Where on the gui can you see the different intensities for each region?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Lookuptable` maps the different intensities used on the segmentation image to their corresponding label. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are a bit more familiar with the dataset and the segmentation images, we can extract the regions of interest from the resting state image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract ROIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to load the required Python libraries. Libraries are like extensions to the base python that add functionality or help to make tasks more convenient to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define paths to the data, segmentation image and where the result will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the subjects resting state image, the segmentation image and the lookuptable using nibabel. (This might take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play a bit around with the images you have just loaded using nibabel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every label get the corresponding activity. Remember that we want to extract the label for each brain region for all time points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How can you get the dimensions of the image? What does each dimension mean?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the time series for a specific region at every time point using the segmentation image and the lookuptable. For each time point you should save the mean activity of the region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results into a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as an exercise lets visualise the matrix here.\n",
    "\n",
    "**Note:** Make sure you have install nilearn in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**Why does the mask look identical to the segmentation mask we used? How can we visualise the mask used only for region?? Folowing the above code which region would this be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualise the connectivity matrix for one time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
