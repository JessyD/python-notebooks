{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook we extracted the time series for different ROIs. However, we are now going to take a step back from that and preprocess our data before we can move on with the analysis.\n",
    "\n",
    "\n",
    "A key point in the analysis of brain image is to have a solid preprocessed image. The preprocessing inclues all the steps that are taken to improve our data and prepare it for statistical analysis. Usual preprocessing steps include: \n",
    " * Corrections for head movement during scanning \n",
    " * Slice corrections\n",
    " * Detection of artifacts during scanning\n",
    " * Normalisation of structural image into MNI space\n",
    " * Filtering\n",
    "\n",
    "We are lucky that a few of this steps have been already performed on the dataset we are using. In this notebook we are going to perform a few important preprocessing steps. To do this, we will use a library called *nipype*, so make sure it is installed in your enviroment.\n",
    "\n",
    "*Nipype* is a really nice library that allows you to use different functions from different existing neuroimaging softwares.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, first we need to load the required Python libraries. Again, make sure you have them all installed in your virtual enviroment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "from IPython.display import Image\n",
    "\n",
    "from nipype.interfaces.fsl import GLM, MeanImage, BinaryMaths, FSLCommand, TemporalFilter\n",
    "from nipype.interfaces.utility import IdentityInterface\n",
    "import nipype.pipeline.engine as pe\n",
    "from nipype import Node, Workflow\n",
    "from nipype.interfaces.io import DataSink, DataGrabber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If you are having problems loading nipype you shoul do the following:\n",
    "- install ipykernel on your virtual enviroment by doing:\n",
    "`conda install ipykernel`\n",
    "- run in the terminal (change my-virtualenv-name):\n",
    "`python -m ipykernel install --user --name=my-virtualenv-name`\n",
    "- Then inside your notebook click on `Kernel>Change Kernel>my-virtualenv-name`\n",
    "\n",
    "If you are not having problems than just ignore this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then set up the paths to our data and important variables. You should change them accordingly, so that they match your paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "base_path_data = os.path.join(os.path.sep, 'group', 'dynamics', 'HCP')\n",
    "data_out_dir = os.path.join(os.path.sep, 'home', 'jdafflon', 'code', 'msc_project', 'patrycja', 'data_out')\n",
    "\n",
    "\n",
    "LR_or_RL = 'rfMRI_REST2_LR'\n",
    "subjects_list = ['100307']\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "\n",
    "segmentation_image_path = os.path.join( os.path.sep, 'group', 'dynamics', 'scz_dynamics', 'ucla-la5', 'data_in', 'voi_extraction', 'seg_aparc_82roi_2mm.nii.gz')\n",
    "lookuptable_file_path = os.path.join(os.path.sep, 'group', 'dynamics', 'scz_dynamics', 'ucla-la5', 'data_in', 'voi_extraction','LookupTable')\n",
    "non_preprocessed_image_path = os.path.join(base_path_data, subjects_list[0], 'MNINonLinear', 'Results', LR_or_RL, 'rfMRI_REST2_LR.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now do some corrections for motion on the dataset. Subject head movement, during the experiment is a major source of artefact in fMRI data. Changes in pixel intensity at the edges of the brain, upon even slight movement, can be far greater than the BOLD activation response. It is common therefore in fMRI data analysis to perform some correction which reduces this effect.\n",
    "\n",
    "Luckly, the motion parameters have already been calculated for us, so all we need to do is load them. And check the shape, for good practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load motion regressors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nipype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will start using nipype. There are different ways of using nipype, here we will create a workflow where each step of our preprocessing pipeline will be composed by a node. Therefore we will need to create the basics for your Nodes in nipype.\n",
    "\n",
    "If you want to get a better insight how a piple is create in nipype you can take a look [here]( http://miykael.github.io/nipype-beginner-s-guide/firstSteps.html). But I will save you the work of creating a pipeline and do everything here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go into more details of how to run the preprocessing pipeline in nipype. Let's take a look into the temporal filtering, which is an important step in the preprocessing. \n",
    "\n",
    "Temporal Filtering allow us to improve the signal-to-noise ratio of our data. It not only removes high frequency fluctuations but also scanner drifts from the data.\n",
    "\n",
    "There are mainly three types of filters: **high-pass filters**, **low-pass filters** and **band-pass filters**.\n",
    "While high-pass filtering will remove low frequency variations in the data, the low-pass filter will remove high frequency in the data. The band-pass filter will remove the frequecies that are outside the specified range.\n",
    "\n",
    "For this preprocessing we wil perform a band-pass filter.\n",
    "To do this we will need to find the TR of our data. The TR corresponds to the repetition time of our MRI sequence and can be read up from the data.\n",
    "\n",
    "**Question:** Find out the TR of the current dataset. Hint: Try to call the function `fslinfo` on your resting state image or alternatively you can look up the documentation on the HCP website (where we have downloaded the data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Band-pass filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spontaneous activity have been observed in the resting state in a low frequency range of [0.01–0.1] Hz. Therefore, we will perform a banpass filter to filter only the frequencies that in the range that we are interested in. Take a look at this [paper](http://www.sciencedirect.com/science/article/pii/S1053811916307881). It will give you an introduction to dynamic Functional Connectivity which we will use in the next notebook and in idea of what are those spontaneous fluctuations.\n",
    "\n",
    "Let's get back to our analysis. Let's say we want to create a band-pass filter between 0.04 Hz and 0.1. How can we do it?\n",
    "\n",
    "This example assumes that the TR is 2, which is **not** the case for this dataset but using the TR information you got from your data set you should be able to calcultate it.\n",
    "\n",
    "* Lower band of the banp-pass filter:\n",
    "\n",
    "low_pass = $\\frac{\\frac{1}{TR}}{filter in Hz} = \\frac{\\frac{1}{2s}}{0.04 1/s} = 12.5 $\n",
    "However, as the fsl temporal filter takes the sigma HWHM and not the FWHM, we will need to divide this value by 2.\n",
    "low_pass_filter = $\\frac{12.5}{2} = 6.25$\n",
    "\n",
    "* Higher band of the band-pass filter:\n",
    "A similar calculation is one using the *high pass filter* just change the 0.04 Hz for 0.1 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find TR of the dataset\n",
    "# TR = ??? (in seconds)\n",
    "\n",
    "lowpass_hz = 0.04\n",
    "highpass_hz = 0.1\n",
    "\n",
    "lowpass_sigma = round((1/TR)/(lowpass_hz * 2),2)\n",
    "highpass_sigma = round((1/TR)/(highpass_hz * 2),2)\n",
    "\n",
    "print('low-pass sigma:', lowpass_sigma)\n",
    "print('high-pass sigma:', highpass_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we might want to change this boundary in the future we are going to define a function that takes a list of frequencies as input for the preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing_pipeline(lowpass_sigma_list ,highpass_sigma_list):\n",
    "    # Create input node. This is where you are specify where you data comes from.\n",
    "    infosource = Node(interface=IdentityInterface(fields=['subject_id']), name='InfoSource')\n",
    "    infosource.iterables = ('subject_id', subjects_list)\n",
    "    datasource = Node(interface=DataGrabber(infields=['subject_id'],\n",
    "                 outfields=['epi']), name='datasource')\n",
    "    datasource.inputs.base_directory = base_path_data\n",
    "    datasource.inputs.template = '*'\n",
    "    datasource.inputs.sort_filelist = True\n",
    "    datasource.inputs.field_template = dict(epi=os.path.join('%s', 'MNINonLinear', 'Results', LR_or_RL, 'rfMRI_REST2_LR.nii.gz'))    \n",
    "\n",
    "    # Create data sink. This is where your data is going to be saved.\n",
    "    data_sink = Node(DataSink(), name='DataSink')\n",
    "    data_sink.inputs.base_directory = os.path.join(data_out_dir, 'preprocessing_out')\n",
    "    substitutions = [('_subject_id', '')]\n",
    "    \n",
    "    # NODE 1:\n",
    "    # We will use a General Linear Model (GLM) to regress activity related to movement.\n",
    "    # To do this we will use the motion parametrs we have from our dataset.\n",
    "    glm = Node(GLM(), name='GLM')\n",
    "    glm.inputs.design = motion_parameter_file\n",
    "    glm.inputs.demean = True\n",
    "    glm.inputs.out_res_name = 'residuals.nii.gz' \n",
    "    glm.inputs.out_file = 'glm_betas.nii.gz'\n",
    "\n",
    "    # NODE 2:\n",
    "    # This node performs the temporal filtering.\n",
    "    tmp_filt = Node(TemporalFilter(), name='TemporalFilter')\n",
    "    tmp_filt.iterables = [('lowpass_sigma', lowpass_sigma_list), \n",
    "                          ('highpass_sigma', highpass_sigma_list)]\n",
    "\n",
    "    # Node 3:\n",
    "    # Get mean image. Thi is only needed to get a pretty picture at the end\n",
    "    mean_img = Node(MeanImage(), name='MeanImage')\n",
    "\n",
    "    # Node 4:\n",
    "    # Add the mean image to get a pretty picture\n",
    "    add_mean = Node(BinaryMaths(), name='AddMean')\n",
    "    add_mean.inputs.operation='add'\n",
    "    add_mean.inputs.terminal_output='file'\n",
    "\n",
    "    # Now that we have defined all nodes we will have to combine them. \n",
    "    preproc = Workflow(name='preprocessing')\n",
    "    preproc.base_dir = data_out_dir\n",
    "    preproc.connect([\n",
    "        (infosource, datasource, [('subject_id', 'subject_id'  )] ),\n",
    "        (datasource, glm,        [('epi'       , 'in_file'     )] ),\n",
    "        (glm,        tmp_filt,   [('out_res'   , 'in_file'     )] ),\n",
    "        (tmp_filt,  data_sink,   [('out_file'  , 'tmp_filt'    )] ),\n",
    "        (tmp_filt,  add_mean,    [('out_file'  , 'in_file'     )] ),\n",
    "        (datasource, mean_img,   [('epi'       , 'in_file'     )] ),\n",
    "        (mean_img,   add_mean,   [('out_file'  , 'operand_file')] ),\n",
    "        (add_mean,   data_sink,  [('out_file'  , 'meaned_image' )] ),\n",
    "    ])\n",
    "    preproc.write_graph(os.path.join(data_out_dir, 'workflow_graph'))\n",
    "    preproc.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now call our pre-processing function with the correct input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "highpass_sigma_list = [highpass_sigma]\n",
    "lowpass_sigma_list = [lowpass_sigma]\n",
    "\n",
    "preprocessing_pipeline(lowpass_sigma_list,highpass_sigma_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot below the graph that sumarise our current preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot png image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Where is the temporal filtered and demeaned image stored, and where is the image where the mean is added stored? Write down the path to the filtered image and name your variable as `path_to_processed_image`. We are going to need this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract ROIs from the preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Use the code from the 1st python notebook to extract the ROIs for the preprocessed data. The idea is the same as from the 1st noteboook. You are supposed to iterate over the regions, find their intensities and then extract the time series from the resting state image. \n",
    "\n",
    "However, this time this code will be englobe in a function. So you will need to transform the code you have written into a function. You should pass the image of interest, the lookuptable and the segmentation image as arguments.  The function should return the average time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Define here the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined the function we can call it in order to extract the ROIs for both the preprocessed and not preprocessed image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the preprocessed, the non-preprocessed and the segmentation image using nibabel before you pass them to the function. Remember to also load the lookuptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Call the function you defined twice. Once you will pass the preprocessed image and for the other the non preprocessed\n",
    "#image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our analysis. We are concerned about how the correlation between the different ROIs change over time.\n",
    "\n",
    "**Question:** Visualise the correlation matrix for the preprocessed and not preprocessed image using `np.corrcoef`. Do you notice any difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot 2 images side by side\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_patrycja",
   "language": "python",
   "name": "msc_patrycja"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
